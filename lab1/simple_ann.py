import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader

def excel_to_tensors(file_path, target_column, test_size=0.2, batch_size=32):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Excel ‡πÄ‡∏õ‡πá‡∏ô PyTorch Tensors ‡∏û‡∏£‡πâ‡∏≠‡∏° DataLoader
    
    Args:
        file_path (str): path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Excel
        target_column (str): ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô target
        test_size (float): ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test (default: 0.2)
        batch_size (int): ‡∏Ç‡∏ô‡∏≤‡∏î batch (default: 32)
    
    Returns:
        dict: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
    """
    print(f"üìÅ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {file_path}")
    
    # 1. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Excel
    df = pd.read_excel(file_path)
    print(f"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {df.shape[0]} rows, {df.shape[1]} columns")
    
    # 2. ‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏•‡∏∞ target
    X = df.drop(columns=[target_column])
    y = df[target_column]
    
    # 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ categorical columns (One-hot encoding)
    categorical_cols = X.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        print(f"üîß One-hot encoding: {list(categorical_cols)}")
        X = pd.get_dummies(X, columns=categorical_cols)
    
    # 4. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy
    X_np = X.values.astype(np.float32)
    y_np = y.values.astype(np.float32)
    
    # 5. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X_np, y_np, test_size=test_size, random_state=42
    )
    print(f"üìä Train: {X_train.shape[0]}, Test: {X_test.shape[0]}")
    
    # 6. Feature scaling
    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    
    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
    print("‚öñÔ∏è Feature scaling ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
    # 7. ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PyTorch tensors
    X_train_tensor = torch.from_numpy(X_train_scaled).float()
    X_test_tensor = torch.from_numpy(X_test_scaled).float()
    y_train_tensor = torch.from_numpy(y_train_scaled).float()
    y_test_tensor = torch.from_numpy(y_test_scaled).float()
    
    # 8. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    print(f"üöÄ PyTorch tensors ‡∏û‡∏£‡πâ‡∏≠‡∏°! Features: {X_train_tensor.shape[1]}")
    
    return {
        'X_train': X_train_tensor,
        'X_test': X_test_tensor, 
        'y_train': y_train_tensor,
        'y_test': y_test_tensor,
        'train_loader': train_loader,
        'test_loader': test_loader,
        'scaler_X': scaler_X,
        'scaler_y': scaler_y,
        'feature_names': list(X.columns),
        'n_features': X_train_tensor.shape[1]
    }

def create_sample_data():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö"""
    np.random.seed(42)
    n = 500
    
    data = {
        'area': np.random.normal(100, 20, n),
        'rooms': np.random.randint(1, 5, n),
        'age': np.random.randint(0, 30, n),
        'location': np.random.choice(['A', 'B', 'C'], n),
        'price': np.random.normal(200000, 50000, n)
    }
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á relationship
    data['price'] = (data['area'] * 2000 + 
                    data['rooms'] * 10000 - 
                    data['age'] * 500 + 
                    np.random.normal(0, 5000, n))
    
    df = pd.DataFrame(data)
    df.to_excel('sample_data.xlsx', index=False)
    print("üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á sample_data.xlsx ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    return df

def main():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    print("=" * 50)
    print("Excel to PyTorch Tensors - Simple Version")
    print("=" * 50)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    df_sample = create_sample_data()
    print(f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n{df_sample.head()}")
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô tensors
    data = excel_to_tensors('sample_data.xlsx', target_column='price')
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print(f"\nüìà ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    print(f"Features: {data['n_features']}")
    print(f"Feature names: {data['feature_names']}")
    print(f"X_train shape: {data['X_train'].shape}")
    print(f"y_train shape: {data['y_train'].shape}")
    print(f"Train batches: {len(data['train_loader'])}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö DataLoader
    print(f"\nüîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö DataLoader:")
    for i, (batch_X, batch_y) in enumerate(data['train_loader']):
        print(f"Batch {i+1}: X{batch_X.shape}, y{batch_y.shape}")
        if i == 1:  # ‡πÅ‡∏™‡∏î‡∏á 2 batch ‡πÅ‡∏£‡∏Å
            break
    
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö neural network
    import torch.nn as nn
    
    class SimpleNet(nn.Module):
        def __init__(self, n_features):
            super().__init__()
            self.linear = nn.Linear(n_features, 1)
        
        def forward(self, x):
            return self.linear(x)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á model ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    model = SimpleNet(data['n_features'])
    sample_input = data['X_train'][:5]
    
    with torch.no_grad():
        predictions = model(sample_input)
        
    print(f"\nüß† ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Neural Network:")
    print(f"Model input shape: {sample_input.shape}")
    print(f"Model predictions: {predictions.flatten()[:3].numpy()}")
    print(f"Actual values: {data['y_train'][:3].numpy()}")
    
    print(f"\n‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deep Learning")

if __name__ == "__main__":
    main()